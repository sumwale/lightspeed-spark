/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

apply plugin: 'scala'
apply plugin: 'de.undercouch.download'

compileScala.options.encoding = 'UTF-8'
// fix scala+java mix to all use compileScala which uses correct dependency order
sourceSets.main.scala.srcDir 'src/main/java'
sourceSets.test.scala.srcDirs = [ 'src/test/java', 'src/test/scala' ]
sourceSets.main.java.srcDirs = []
sourceSets.test.java.srcDirs = []

dependencies {
  compileOnly coreLibraries.common
  compileOnly coreLibraries.spark

  compile project(path: ':lightspeed-common', configuration: 'shadow')
}

task packageScalaDocs(type: Jar, dependsOn: scaladoc) {
  classifier = 'javadoc'
  from scaladoc
}
if (rootProject.hasProperty('enablePublish')) {
  artifacts {
    archives packageScalaDocs, packageSources
  }
}

scalaTest {
  dependsOn ':cleanScalaTest'
  doFirst {
    // cleanup files since scalatest plugin does not honour workingDir yet
    cleanIntermediateFiles(project.path)
  }
  doLast {
    // cleanup files since scalatest plugin does not honour workingDir yet
    cleanIntermediateFiles(project.path)
  }
}

def downloadApacheSparkDist(String ver, String distName, String prodDir) {
  return tasks.create("downloadApache${ver}SparkDist", Download) {
    outputs.files "${prodDir}.tgz", "${prodDir}/README.md"

    src "http://archive.apache.org/dist/spark/spark-${ver}/${distName}.tgz"
    dest sparkDistDir
    onlyIfNewer true

    doFirst {
      mkdir(sparkDistDir)
    }
  }
}

def taskGetApacheSparkDist(String ver, String distName, String prodDir) {
  return tasks.create("getApacheSpark${ver}Dist") {
    dependsOn downloadApacheSparkDist(ver, distName, prodDir)

    outputs.files "${prodDir}.tgz", "${prodDir}/README.md"

    doLast {
      if (osName.isWindows()) {
        copy {
          from tarTree(resources.gzip("${sparkDistDir}/${distName}.tgz"))
          into sparkDistDir
        }
      } else {
        // gradle tarTree does not preserve symlinks (GRADLE-2844)
        exec {
          executable 'tar'
          args 'xzf', "${distName}.tgz"
          workingDir = sparkDistDir
        }
      }
    }
  }
}

task getApacheSparkDist {
  dependsOn taskGetApacheSparkDist(sparkVersion, sparkDistName, sparkProductDir)
}

test.dependsOn ':cleanJUnit'
check.dependsOn test, scalaTest

archivesBaseName = "lightspeed-core-spark${sparkVersion}_${scalaBinaryVersion}"

jar.classifier = 'only'

shadowJar {
  classifier = null
  zip64 = true

  configurations = [ project.configurations.runtime ]

  mergeServiceFiles()
  exclude 'log4j.properties'

  if (rootProject.hasProperty('enablePublish')) {
    createdBy = vendorName
  } else {
    createdBy = System.getProperty('user.name')
  }
  manifest {
    attributes(
      'Manifest-Version'  : '1.0',
      'Created-By'        : createdBy,
      'Title'             : archivesBaseName,
      'Version'           : version,
      'Vendor'            : vendorName
    )
  }
}

// write the POM for spark-package
task sparkPackagePom(dependsOn: shadowJar) { doLast {
  file("${rootProject.buildDir}/distributions").mkdirs()
  pom {
    project {
      groupId 'LightSpeedSpark'
      artifactId "lightspeed-spark${sparkVersion}"
      version "${version}-s_${scalaBinaryVersion}"
      licenses {
        license {
          name 'The Apache Software License, Version 2.0'
          url 'http://www.apache.org/licenses/LICENSE-2.0.txt'
          distribution 'repo'
        }
      }
    }
    whenConfigured { p -> p.dependencies.clear() }
  }.writeTo("${rootProject.buildDir}/distributions/${sparkPackageName}.pom")
  copy {
    from "${buildDir}/libs"
    into "${rootProject.buildDir}/distributions"
    include "${shadowJar.archiveName}"
    rename { filename -> "${sparkPackageName}.jar" }
  }
} }

task sparkPackage(type: Zip, dependsOn: sparkPackagePom) {
  archiveName = "${sparkPackageName}.zip"
  destinationDir = file("${rootProject.buildDir}/distributions")
  outputs.upToDateWhen { false }

  from ("${rootProject.buildDir}/distributions") {
    include "${sparkPackageName}.jar"
    include "${sparkPackageName}.pom"
  }
}
